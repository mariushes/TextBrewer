{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lokwq/TextBrewer/blob/add_note_examples/sst2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMExDS48VN58"
   },
   "source": [
    "This notebook shows how to fine-tune a model on sst-2 dataset and how to distill the model with TextBrewer.\n",
    "\n",
    "Detailed Docs can be find here:\n",
    "https://github.com/airaria/TextBrewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oVTjuvH0rPsT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qqu-aNtc3QgP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer,BertConfig, AutoModelForSequenceClassification,RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset,load_metric\n",
    "from functools import partial\n",
    "from predict_function import predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5ww8ad58D8v"
   },
   "source": [
    "### Prepare dataset to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9-8wYOHG4WVq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/mhessent/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (/home/mhessent/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (/home/mhessent/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset('glue', 'stsb', split='train')#,cache_dir=\"/work/mhessent/cache\")\n",
    "val_dataset = load_dataset('glue', 'stsb', split='validation')#,cache_dir=\"/work/mhessent/cache\")\n",
    "test_dataset = load_dataset('glue', 'stsb', split='test')#,cache_dir=\"/work/mhessent/cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iQSki-hv5Imc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mhessent/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-2a1905efa4704bcb.arrow\n",
      "Loading cached processed dataset at /home/mhessent/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-e194e0b596fcf478.arrow\n",
      "Loading cached processed dataset at /home/mhessent/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-c97e180e5b68e6bf.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
    "val_dataset = val_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
    "test_dataset = test_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
    "\n",
    "val_dataset = val_dataset.remove_columns(['label'])\n",
    "test_dataset = test_dataset.remove_columns(['label'])\n",
    "train_dataset = train_dataset.remove_columns(['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "whL22dsx5QU5"
   },
   "outputs": [],
   "source": [
    "#model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=1)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eH4rBumG5i6S"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af8ad86e84647009d1766c9d0f84b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6a8cd3d6014255b4185cdf1a3f1a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada9e76c23f4484f899bb3b176950f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 128\n",
    "train_dataset = train_dataset.map(lambda e: tokenizer(e['sentence1'],e['sentence2'], truncation=True, padding='max_length', max_length=MAX_LENGTH), batched=True)\n",
    "val_dataset = val_dataset.map(lambda e: tokenizer(e['sentence1'],e['sentence2'], truncation=True, padding='max_length', max_length=MAX_LENGTH), batched=True)\n",
    "test_dataset = test_dataset.map(lambda e: tokenizer(e['sentence1'],e['sentence2'], truncation=True, padding='max_length', max_length=MAX_LENGTH), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Nv-gsKvG5ylO"
   },
   "outputs": [],
   "source": [
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor(3.8000),\n",
       " 'input_ids': tensor([   0,  250,  313,   16,  816,   10,  739, 2342, 4467,    4,    2,    2,\n",
       "          250,  313,   16,  816,   10, 2342, 4467,    4,    2,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor(4.7500),\n",
       " 'input_ids': tensor([   0,  250,  664,  920,   16, 5793,   10, 5253,    4,    2,    2,  250,\n",
       "          920,   16, 5793,   10, 5253,    4,    2,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6jwP2aHv6EU6"
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    metric = load_metric(\"glue\",\"stsb\")\n",
    "    return metric.compute(predictions=preds, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KonAbPBj6NCK"
   },
   "outputs": [],
   "source": [
    "#start training \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='outputs/results',          #output directory\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=3,              \n",
    "    per_device_train_batch_size=32,                #batch size per device during training\n",
    "    per_device_eval_batch_size=32,                #batch size for evaluation\n",
    "    logging_dir='outputs/logs',            \n",
    "    logging_steps=500,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    no_cuda=False,\n",
    "    load_best_model_at_end=True,\n",
    "    # eval_steps=100,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=val_dataset,            \n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "train_out = trainer.train()\n",
    "\n",
    "#after training, you could find traing logs and checpoints in your own dirve. also you can reset the file address in training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "1H8Dod2y6R8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/mhessent/miniconda/envs/thesis_test/lib/python3.8/site-packages/torch/nn/modules/module.py:1385: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#torch.save(model.state_dict(), 'outputs/stsb_teacher_model.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gov66CaFNAgg"
   },
   "source": [
    "### Start distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IA-gwQKNB8fs"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32) #prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YD8qPZmUiTKH"
   },
   "outputs": [],
   "source": [
    "import textbrewer\n",
    "from textbrewer import GeneralDistiller\n",
    "from textbrewer import TrainingConfig, DistillationConfig\n",
    "from transformers import BertForSequenceClassification, BertConfig, AdamW,BertTokenizer, RobertaConfig, RobertaForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.17.0\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(\"roberta-base\", output_hidden_states=True)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45db48310ce94717bee46b72b48b0a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.17.0\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilroberta_config = RobertaConfig.from_pretrained(\"distilroberta-base\", output_hidden_states=True)\n",
    "distilroberta_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4emuX8UK8Mup"
   },
   "source": [
    "Initialize the student model by BertConfig and prepare the teacher model.\n",
    "\n",
    "bert_config_L3.json refers to a 3-layer Bert.\n",
    "\n",
    "bert_config.json refers to a standard 12-layer Bert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "CKLaqSPCiX1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50265\n",
      "50265\n",
      "50265\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(\"roberta-base\", output_hidden_states=True)\n",
    "#config = RobertaConfig.from_json_file('/work/mhessent/TextBrewer/examples/student_config/bert_base_cased_config/bert_config.json')\n",
    "config.output_hidden_states = True\n",
    "#config.vocab_size = len(tokenizer)\n",
    "config.num_labels = 1\n",
    "\n",
    "teacher_model = RobertaForSequenceClassification(config)\n",
    "#teacher_model.load_state_dict(torch.load('/work/mhessent/master_thesis/eval_out/roberta-base/stsb/lr3e-05_bs16_epochs10/torch_state_dict.pt'))\n",
    "teacher_model.load_state_dict(torch.load('outputs/stsb_teacher_model.pt'))\n",
    "\"\"\"\n",
    "model = BertForSequenceClassification.from_pretrained(\"/work/mhessent/master_thesis/eval_out/bert-base-uncased/mnli/lr3e-05_bs32_epochs3/checkpoint-36816\")\n",
    "torch.save(model.state_dict(), 'outputs/hub_mnli_teacher_model.pt')\n",
    "bert_config = BertConfig.from_json_file('/work/mhessent/TextBrewer/examples/student_config/bert_base_cased_config/bert_config.json')\n",
    "bert_config.output_hidden_states = True\n",
    "bert_config.vocab_size = 30522\n",
    "bert_config.num_labels = 3\n",
    "teacher_model = BertForSequenceClassification(bert_config) #, num_labels = 2\n",
    "teacher_model.load_state_dict(torch.load('outputs/hub_mnli_teacher_model.pt'))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "teacher_model = teacher_model.to(device=device)\n",
    "\n",
    "\n",
    "\n",
    "student_config = RobertaConfig.from_pretrained(\"roberta-base\", output_hidden_states=True)\n",
    "student_config.output_hidden_states = True\n",
    "student_config.num_labels = 1\n",
    "student_config.num_hidden_layers = 3\n",
    "#student_config.vocab_size = teacher_model.config.vocab_size\n",
    "\n",
    "student_model = RobertaForSequenceClassification(student_config)\n",
    "student_model = student_model.to(device=device)\n",
    "\n",
    "\n",
    "print(teacher_model.config.vocab_size)\n",
    "print(student_model.config.vocab_size)\n",
    "print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6SuVnpa8RAm"
   },
   "source": [
    "The cell below is to distill the teacher model to student model you prepared.\n",
    "\n",
    "After the code execution is complete, the distilled model will be in 'saved_model' in colab file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CIxaegSUikGX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:17:31 - INFO - Distillation -  Training steps per epoch: 180\n",
      "2022/03/29 14:17:31 - INFO - Distillation -  Checkpoints(step): [0]\n",
      "2022/03/29 14:17:31 - INFO - Distillation -  Epoch 1\n",
      "2022/03/29 14:17:31 - INFO - Distillation -  Length of current epoch in forward batch: 180\n",
      "2022/03/29 14:17:33 - INFO - Distillation -  Global step: 9, epoch step:9\n",
      "2022/03/29 14:17:34 - INFO - Distillation -  Global step: 18, epoch step:18\n",
      "2022/03/29 14:17:36 - INFO - Distillation -  Global step: 27, epoch step:27\n",
      "2022/03/29 14:17:37 - INFO - Distillation -  Global step: 36, epoch step:36\n",
      "2022/03/29 14:17:39 - INFO - Distillation -  Global step: 45, epoch step:45\n",
      "2022/03/29 14:17:41 - INFO - Distillation -  Global step: 54, epoch step:54\n",
      "2022/03/29 14:17:42 - INFO - Distillation -  Global step: 63, epoch step:63\n",
      "2022/03/29 14:17:44 - INFO - Distillation -  Global step: 72, epoch step:72\n",
      "2022/03/29 14:17:45 - INFO - Distillation -  Global step: 81, epoch step:81\n",
      "2022/03/29 14:17:47 - INFO - Distillation -  Global step: 90, epoch step:90\n",
      "2022/03/29 14:17:48 - INFO - Distillation -  Global step: 99, epoch step:99\n",
      "2022/03/29 14:17:50 - INFO - Distillation -  Global step: 108, epoch step:108\n",
      "2022/03/29 14:17:51 - INFO - Distillation -  Global step: 117, epoch step:117\n",
      "2022/03/29 14:17:53 - INFO - Distillation -  Global step: 126, epoch step:126\n",
      "2022/03/29 14:17:55 - INFO - Distillation -  Global step: 135, epoch step:135\n",
      "2022/03/29 14:17:56 - INFO - Distillation -  Global step: 144, epoch step:144\n",
      "2022/03/29 14:17:58 - INFO - Distillation -  Global step: 153, epoch step:153\n",
      "2022/03/29 14:17:59 - INFO - Distillation -  Global step: 162, epoch step:162\n",
      "2022/03/29 14:18:01 - INFO - Distillation -  Global step: 171, epoch step:171\n",
      "2022/03/29 14:18:02 - INFO - Distillation -  Global step: 180, epoch step:180\n",
      "2022/03/29 14:18:02 - INFO - Distillation -  Saving at global step 180, epoch step 180 epoch 1\n",
      "2022/03/29 14:18:04 - INFO - Distillation -  Running callback function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.9424],\n",
      "        [2.9448]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9757],\n",
      "        [2.9587]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9740],\n",
      "        [2.9554]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9558],\n",
      "        [2.9617]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9618],\n",
      "        [2.9602]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9493],\n",
      "        [2.9550]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9513],\n",
      "        [2.9711]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9760],\n",
      "        [2.9768]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9604],\n",
      "        [2.9468]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9739],\n",
      "        [2.9736]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9659],\n",
      "        [2.9698]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9652],\n",
      "        [2.9676]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9741],\n",
      "        [2.9546]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9416],\n",
      "        [2.9781]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9527],\n",
      "        [2.9595]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9645],\n",
      "        [2.9626]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9678],\n",
      "        [2.9469]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9631],\n",
      "        [2.9570]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9637],\n",
      "        [2.9462]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9532],\n",
      "        [2.9522]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9657],\n",
      "        [2.9734]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9607],\n",
      "        [2.9862]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9621],\n",
      "        [2.9752]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9595],\n",
      "        [2.9681]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9690],\n",
      "        [2.9719]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9548],\n",
      "        [2.9766]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9614],\n",
      "        [2.9721]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9662],\n",
      "        [2.9693]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9814],\n",
      "        [2.9871]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9901],\n",
      "        [2.9812]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9809],\n",
      "        [2.9737]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9817],\n",
      "        [2.9713]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9760],\n",
      "        [2.9879]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9872],\n",
      "        [2.9749]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9727],\n",
      "        [2.9739]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9796],\n",
      "        [2.9656]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9806],\n",
      "        [2.9662]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9836],\n",
      "        [2.9773]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9747],\n",
      "        [2.9813]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9673],\n",
      "        [2.9634]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9521],\n",
      "        [2.9617]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9726],\n",
      "        [2.9449]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9479],\n",
      "        [2.9621]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9447],\n",
      "        [2.9623]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9431],\n",
      "        [2.9733]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9389],\n",
      "        [2.9642]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9810],\n",
      "        [2.9415]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:18:09 - INFO - Distillation -  {'pearson': 0.0062128703980162975, 'spearmanr': 0.007232440076709042}\n",
      "2022/03/29 14:18:09 - INFO - Distillation -  Epoch 1 finished\n",
      "2022/03/29 14:18:09 - INFO - Distillation -  Epoch 2\n",
      "2022/03/29 14:18:09 - INFO - Distillation -  Length of current epoch in forward batch: 180\n",
      "2022/03/29 14:18:10 - INFO - Distillation -  Global step: 189, epoch step:9\n",
      "2022/03/29 14:18:12 - INFO - Distillation -  Global step: 198, epoch step:18\n",
      "2022/03/29 14:18:13 - INFO - Distillation -  Global step: 207, epoch step:27\n",
      "2022/03/29 14:18:15 - INFO - Distillation -  Global step: 216, epoch step:36\n",
      "2022/03/29 14:18:17 - INFO - Distillation -  Global step: 225, epoch step:45\n",
      "2022/03/29 14:18:18 - INFO - Distillation -  Global step: 234, epoch step:54\n",
      "2022/03/29 14:18:20 - INFO - Distillation -  Global step: 243, epoch step:63\n",
      "2022/03/29 14:18:21 - INFO - Distillation -  Global step: 252, epoch step:72\n",
      "2022/03/29 14:18:23 - INFO - Distillation -  Global step: 261, epoch step:81\n",
      "2022/03/29 14:18:24 - INFO - Distillation -  Global step: 270, epoch step:90\n",
      "2022/03/29 14:18:26 - INFO - Distillation -  Global step: 279, epoch step:99\n",
      "2022/03/29 14:18:28 - INFO - Distillation -  Global step: 288, epoch step:108\n",
      "2022/03/29 14:18:29 - INFO - Distillation -  Global step: 297, epoch step:117\n",
      "2022/03/29 14:18:31 - INFO - Distillation -  Global step: 306, epoch step:126\n",
      "2022/03/29 14:18:33 - INFO - Distillation -  Global step: 315, epoch step:135\n",
      "2022/03/29 14:18:34 - INFO - Distillation -  Global step: 324, epoch step:144\n",
      "2022/03/29 14:18:36 - INFO - Distillation -  Global step: 333, epoch step:153\n",
      "2022/03/29 14:18:37 - INFO - Distillation -  Global step: 342, epoch step:162\n",
      "2022/03/29 14:18:39 - INFO - Distillation -  Global step: 351, epoch step:171\n",
      "2022/03/29 14:18:41 - INFO - Distillation -  Global step: 360, epoch step:180\n",
      "2022/03/29 14:18:41 - INFO - Distillation -  Saving at global step 360, epoch step 180 epoch 2\n",
      "2022/03/29 14:18:42 - INFO - Distillation -  Running callback function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.0988],\n",
      "        [3.0961]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1558],\n",
      "        [3.0966]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1494],\n",
      "        [3.0932]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1175],\n",
      "        [3.1200]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1316],\n",
      "        [3.1344]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0954],\n",
      "        [3.0989]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1013],\n",
      "        [3.1444]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1452],\n",
      "        [3.1720]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1359],\n",
      "        [3.1237]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1636],\n",
      "        [3.1780]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1587],\n",
      "        [3.1486]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1434],\n",
      "        [3.1531]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1513],\n",
      "        [3.1263]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1073],\n",
      "        [3.1741]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1328],\n",
      "        [3.1341]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1526],\n",
      "        [3.1506]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1577],\n",
      "        [3.0837]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1443],\n",
      "        [3.1356]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1308],\n",
      "        [3.1227]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1195],\n",
      "        [3.1076]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1629],\n",
      "        [3.1799]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1707],\n",
      "        [3.1888]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1640],\n",
      "        [3.1672]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1621],\n",
      "        [3.1664]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1733],\n",
      "        [3.1789]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1403],\n",
      "        [3.1881]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1617],\n",
      "        [3.1645]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1734],\n",
      "        [3.1765]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1805],\n",
      "        [3.1895]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1976],\n",
      "        [3.1885]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1871],\n",
      "        [3.1673]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1888],\n",
      "        [3.1741]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1831],\n",
      "        [3.1862]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1981],\n",
      "        [3.1734]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1737],\n",
      "        [3.1911]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1861],\n",
      "        [3.1773]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1893],\n",
      "        [3.1725]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1933],\n",
      "        [3.1812]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1767],\n",
      "        [3.1680]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1735],\n",
      "        [3.1544]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1219],\n",
      "        [3.1417]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1653],\n",
      "        [3.1295]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1182],\n",
      "        [3.1568]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1378],\n",
      "        [3.1316]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1157],\n",
      "        [3.1518]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1125],\n",
      "        [3.1586]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1757],\n",
      "        [3.1423]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:18:44 - INFO - Distillation -  {'pearson': 0.06229257444329203, 'spearmanr': 0.06758987962503035}\n",
      "2022/03/29 14:18:44 - INFO - Distillation -  Epoch 2 finished\n",
      "2022/03/29 14:18:44 - INFO - Distillation -  Epoch 3\n",
      "2022/03/29 14:18:44 - INFO - Distillation -  Length of current epoch in forward batch: 180\n",
      "2022/03/29 14:18:46 - INFO - Distillation -  Global step: 369, epoch step:9\n",
      "2022/03/29 14:18:47 - INFO - Distillation -  Global step: 378, epoch step:18\n",
      "2022/03/29 14:18:49 - INFO - Distillation -  Global step: 387, epoch step:27\n",
      "2022/03/29 14:18:51 - INFO - Distillation -  Global step: 396, epoch step:36\n",
      "2022/03/29 14:18:52 - INFO - Distillation -  Global step: 405, epoch step:45\n",
      "2022/03/29 14:18:54 - INFO - Distillation -  Global step: 414, epoch step:54\n",
      "2022/03/29 14:18:55 - INFO - Distillation -  Global step: 423, epoch step:63\n",
      "2022/03/29 14:18:57 - INFO - Distillation -  Global step: 432, epoch step:72\n",
      "2022/03/29 14:18:59 - INFO - Distillation -  Global step: 441, epoch step:81\n",
      "2022/03/29 14:19:00 - INFO - Distillation -  Global step: 450, epoch step:90\n",
      "2022/03/29 14:19:02 - INFO - Distillation -  Global step: 459, epoch step:99\n",
      "2022/03/29 14:19:03 - INFO - Distillation -  Global step: 468, epoch step:108\n",
      "2022/03/29 14:19:05 - INFO - Distillation -  Global step: 477, epoch step:117\n",
      "2022/03/29 14:19:07 - INFO - Distillation -  Global step: 486, epoch step:126\n",
      "2022/03/29 14:19:08 - INFO - Distillation -  Global step: 495, epoch step:135\n",
      "2022/03/29 14:19:10 - INFO - Distillation -  Global step: 504, epoch step:144\n",
      "2022/03/29 14:19:12 - INFO - Distillation -  Global step: 513, epoch step:153\n",
      "2022/03/29 14:19:13 - INFO - Distillation -  Global step: 522, epoch step:162\n",
      "2022/03/29 14:19:15 - INFO - Distillation -  Global step: 531, epoch step:171\n",
      "2022/03/29 14:19:16 - INFO - Distillation -  Global step: 540, epoch step:180\n",
      "2022/03/29 14:19:16 - INFO - Distillation -  Saving at global step 540, epoch step 180 epoch 3\n",
      "2022/03/29 14:19:18 - INFO - Distillation -  Running callback function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1054],\n",
      "        [3.0991]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3637],\n",
      "        [2.9882]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1327],\n",
      "        [2.9827]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0415],\n",
      "        [3.0722]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1510],\n",
      "        [3.2015]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0072],\n",
      "        [2.9972]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0036],\n",
      "        [3.1027]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0936],\n",
      "        [3.2958]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2942],\n",
      "        [3.2917]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2353],\n",
      "        [3.4094]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3876],\n",
      "        [3.3594]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3227],\n",
      "        [3.3568]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1369],\n",
      "        [3.1951]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2562],\n",
      "        [3.4001]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3330],\n",
      "        [3.3044]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3655],\n",
      "        [3.3557]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2403],\n",
      "        [2.9787]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2261],\n",
      "        [3.2314]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3137],\n",
      "        [3.3336]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2921],\n",
      "        [3.0798]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2644],\n",
      "        [3.3911]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2941],\n",
      "        [3.3362]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2824],\n",
      "        [3.3621]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2530],\n",
      "        [3.3246]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3440],\n",
      "        [3.4147]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1330],\n",
      "        [3.4348]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2469],\n",
      "        [3.2582]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3363],\n",
      "        [3.4170]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2856],\n",
      "        [3.4236]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4333],\n",
      "        [3.4219]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3237],\n",
      "        [3.2354]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3331],\n",
      "        [3.3096]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4181],\n",
      "        [3.4124]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4408],\n",
      "        [3.3213]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3928],\n",
      "        [3.4173]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4204],\n",
      "        [3.4070]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4313],\n",
      "        [3.3977]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4290],\n",
      "        [3.3994]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3837],\n",
      "        [3.2773]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3964],\n",
      "        [3.2382]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2854],\n",
      "        [3.3587]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4027],\n",
      "        [3.3248]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3044],\n",
      "        [3.3833]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3505],\n",
      "        [3.3105]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:19:20 - INFO - Distillation -  {'pearson': 0.13227673441926008, 'spearmanr': 0.15243127450458419}\n",
      "2022/03/29 14:19:20 - INFO - Distillation -  Epoch 3 finished\n",
      "2022/03/29 14:19:20 - INFO - Distillation -  Epoch 4\n",
      "2022/03/29 14:19:20 - INFO - Distillation -  Length of current epoch in forward batch: 180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.2401],\n",
      "        [3.3621]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2989],\n",
      "        [3.3802]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4108],\n",
      "        [3.3859]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:19:22 - INFO - Distillation -  Global step: 549, epoch step:9\n",
      "2022/03/29 14:19:23 - INFO - Distillation -  Global step: 558, epoch step:18\n",
      "2022/03/29 14:19:25 - INFO - Distillation -  Global step: 567, epoch step:27\n",
      "2022/03/29 14:19:26 - INFO - Distillation -  Global step: 576, epoch step:36\n",
      "2022/03/29 14:19:28 - INFO - Distillation -  Global step: 585, epoch step:45\n",
      "2022/03/29 14:19:30 - INFO - Distillation -  Global step: 594, epoch step:54\n",
      "2022/03/29 14:19:31 - INFO - Distillation -  Global step: 603, epoch step:63\n",
      "2022/03/29 14:19:33 - INFO - Distillation -  Global step: 612, epoch step:72\n",
      "2022/03/29 14:19:34 - INFO - Distillation -  Global step: 621, epoch step:81\n",
      "2022/03/29 14:19:36 - INFO - Distillation -  Global step: 630, epoch step:90\n",
      "2022/03/29 14:19:38 - INFO - Distillation -  Global step: 639, epoch step:99\n",
      "2022/03/29 14:19:40 - INFO - Distillation -  Global step: 648, epoch step:108\n",
      "2022/03/29 14:19:41 - INFO - Distillation -  Global step: 657, epoch step:117\n",
      "2022/03/29 14:19:43 - INFO - Distillation -  Global step: 666, epoch step:126\n",
      "2022/03/29 14:19:45 - INFO - Distillation -  Global step: 675, epoch step:135\n",
      "2022/03/29 14:19:46 - INFO - Distillation -  Global step: 684, epoch step:144\n",
      "2022/03/29 14:19:48 - INFO - Distillation -  Global step: 693, epoch step:153\n",
      "2022/03/29 14:19:50 - INFO - Distillation -  Global step: 702, epoch step:162\n",
      "2022/03/29 14:19:51 - INFO - Distillation -  Global step: 711, epoch step:171\n",
      "2022/03/29 14:19:53 - INFO - Distillation -  Global step: 720, epoch step:180\n",
      "2022/03/29 14:19:53 - INFO - Distillation -  Saving at global step 720, epoch step 180 epoch 4\n",
      "2022/03/29 14:19:55 - INFO - Distillation -  Running callback function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.8005],\n",
      "        [2.7488]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4294],\n",
      "        [2.4678]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.8322],\n",
      "        [2.4491]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.5718],\n",
      "        [2.6507]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.8942],\n",
      "        [2.9740]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.4484],\n",
      "        [2.5208]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.3950],\n",
      "        [2.7477]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.6484],\n",
      "        [3.1513]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2225],\n",
      "        [3.1000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0653],\n",
      "        [3.5214]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.5290],\n",
      "        [3.4382]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1890],\n",
      "        [3.3816]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.8533],\n",
      "        [2.9493]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0268],\n",
      "        [3.5393]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3642],\n",
      "        [3.1321]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3598],\n",
      "        [3.4387]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0590],\n",
      "        [2.4787]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9183],\n",
      "        [3.0596]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2730],\n",
      "        [3.3397]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2124],\n",
      "        [2.6647]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0659],\n",
      "        [3.3475]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1233],\n",
      "        [3.2686]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1274],\n",
      "        [3.3262]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0585],\n",
      "        [3.2861]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2537],\n",
      "        [3.5625]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.8712],\n",
      "        [3.6150]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0685],\n",
      "        [2.9628]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1933],\n",
      "        [3.5870]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1432],\n",
      "        [3.5634]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.5973],\n",
      "        [3.4327]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2558],\n",
      "        [3.0625]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1799],\n",
      "        [3.0760]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.5391],\n",
      "        [3.5549]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.5695],\n",
      "        [3.2533]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4755],\n",
      "        [3.4087]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.5963],\n",
      "        [3.4732]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6267],\n",
      "        [3.4938]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4557],\n",
      "        [3.3977]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3907],\n",
      "        [3.0774]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.5031],\n",
      "        [2.9047]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0835],\n",
      "        [3.3839]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.5629],\n",
      "        [3.3542]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:19:57 - INFO - Distillation -  {'pearson': 0.15934024242720646, 'spearmanr': 0.17108323906281053}\n",
      "2022/03/29 14:19:57 - INFO - Distillation -  Epoch 4 finished\n",
      "2022/03/29 14:19:57 - INFO - Distillation -  Epoch 5\n",
      "2022/03/29 14:19:57 - INFO - Distillation -  Length of current epoch in forward batch: 180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.2574],\n",
      "        [3.4611]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4115],\n",
      "        [3.3222]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0445],\n",
      "        [3.3994]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2287],\n",
      "        [3.4542]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6090],\n",
      "        [3.5566]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:19:59 - INFO - Distillation -  Global step: 729, epoch step:9\n",
      "2022/03/29 14:20:00 - INFO - Distillation -  Global step: 738, epoch step:18\n",
      "2022/03/29 14:20:02 - INFO - Distillation -  Global step: 747, epoch step:27\n",
      "2022/03/29 14:20:04 - INFO - Distillation -  Global step: 756, epoch step:36\n",
      "2022/03/29 14:20:05 - INFO - Distillation -  Global step: 765, epoch step:45\n",
      "2022/03/29 14:20:07 - INFO - Distillation -  Global step: 774, epoch step:54\n",
      "2022/03/29 14:20:09 - INFO - Distillation -  Global step: 783, epoch step:63\n",
      "2022/03/29 14:20:10 - INFO - Distillation -  Global step: 792, epoch step:72\n",
      "2022/03/29 14:20:12 - INFO - Distillation -  Global step: 801, epoch step:81\n",
      "2022/03/29 14:20:14 - INFO - Distillation -  Global step: 810, epoch step:90\n",
      "2022/03/29 14:20:16 - INFO - Distillation -  Global step: 819, epoch step:99\n",
      "2022/03/29 14:20:17 - INFO - Distillation -  Global step: 828, epoch step:108\n",
      "2022/03/29 14:20:19 - INFO - Distillation -  Global step: 837, epoch step:117\n",
      "2022/03/29 14:20:21 - INFO - Distillation -  Global step: 846, epoch step:126\n",
      "2022/03/29 14:20:22 - INFO - Distillation -  Global step: 855, epoch step:135\n",
      "2022/03/29 14:20:24 - INFO - Distillation -  Global step: 864, epoch step:144\n",
      "2022/03/29 14:20:25 - INFO - Distillation -  Global step: 873, epoch step:153\n",
      "2022/03/29 14:20:27 - INFO - Distillation -  Global step: 882, epoch step:162\n",
      "2022/03/29 14:20:29 - INFO - Distillation -  Global step: 891, epoch step:171\n",
      "2022/03/29 14:20:30 - INFO - Distillation -  Global step: 900, epoch step:180\n",
      "2022/03/29 14:20:30 - INFO - Distillation -  Saving at global step 900, epoch step 180 epoch 5\n",
      "2022/03/29 14:20:31 - INFO - Distillation -  Running callback function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1315],\n",
      "        [ 0.1668]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.5116],\n",
      "        [-0.2669]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.4240],\n",
      "        [-0.7050]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.6668],\n",
      "        [-0.4031]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4880],\n",
      "        [0.4843]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.7998],\n",
      "        [-0.2885]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.5885],\n",
      "        [-0.1288]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.3194],\n",
      "        [ 0.8376]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6410],\n",
      "        [0.8590]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2569],\n",
      "        [1.4199]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.4414],\n",
      "        [2.3851]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.8136],\n",
      "        [0.9844]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.4715],\n",
      "        [ 0.7792]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2161],\n",
      "        [2.1232]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.3293],\n",
      "        [0.4289]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.3652],\n",
      "        [1.3453]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.6149],\n",
      "        [-0.5373]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2795],\n",
      "        [0.1814]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.3812],\n",
      "        [1.4697]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.7756],\n",
      "        [-0.3574]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.2440],\n",
      "        [0.7978]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.9840],\n",
      "        [2.1491]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.0017],\n",
      "        [1.6623]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6606],\n",
      "        [0.8722]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.0987],\n",
      "        [1.6033]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.3453],\n",
      "        [ 3.1725]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.0189],\n",
      "        [0.4254]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3074],\n",
      "        [1.6589]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6309],\n",
      "        [2.0242]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.7118],\n",
      "        [1.8449]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.7265],\n",
      "        [0.4545]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.1192],\n",
      "        [1.2923]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.1300],\n",
      "        [2.8854]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.4788],\n",
      "        [1.0654]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.3160],\n",
      "        [1.5625]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.2567],\n",
      "        [2.4534]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.3912],\n",
      "        [0.9881]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[ 2.8178],\n",
      "        [-0.3573]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4817],\n",
      "        [0.9776]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.9527],\n",
      "        [0.5554]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.2098],\n",
      "        [0.9396]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.0488],\n",
      "        [1.3901]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.1914],\n",
      "        [1.2149]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.8593],\n",
      "        [1.7019]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:20:34 - INFO - Distillation -  {'pearson': 0.17703075060689014, 'spearmanr': 0.16909775889461354}\n",
      "2022/03/29 14:20:34 - INFO - Distillation -  Epoch 5 finished\n",
      "2022/03/29 14:20:34 - INFO - Distillation -  Epoch 6\n",
      "2022/03/29 14:20:34 - INFO - Distillation -  Length of current epoch in forward batch: 180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9097],\n",
      "        [1.2845]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.1246],\n",
      "        [2.0121]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.9054],\n",
      "        [2.7647]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:20:36 - INFO - Distillation -  Global step: 909, epoch step:9\n",
      "2022/03/29 14:20:37 - INFO - Distillation -  Global step: 918, epoch step:18\n",
      "2022/03/29 14:20:39 - INFO - Distillation -  Global step: 927, epoch step:27\n",
      "2022/03/29 14:20:41 - INFO - Distillation -  Global step: 936, epoch step:36\n",
      "2022/03/29 14:20:42 - INFO - Distillation -  Global step: 945, epoch step:45\n",
      "2022/03/29 14:20:44 - INFO - Distillation -  Global step: 954, epoch step:54\n",
      "2022/03/29 14:20:45 - INFO - Distillation -  Global step: 963, epoch step:63\n",
      "2022/03/29 14:20:47 - INFO - Distillation -  Global step: 972, epoch step:72\n",
      "2022/03/29 14:20:49 - INFO - Distillation -  Global step: 981, epoch step:81\n",
      "2022/03/29 14:20:51 - INFO - Distillation -  Global step: 990, epoch step:90\n",
      "2022/03/29 14:20:52 - INFO - Distillation -  Global step: 999, epoch step:99\n",
      "2022/03/29 14:20:54 - INFO - Distillation -  Global step: 1008, epoch step:108\n",
      "2022/03/29 14:20:56 - INFO - Distillation -  Global step: 1017, epoch step:117\n",
      "2022/03/29 14:20:57 - INFO - Distillation -  Global step: 1026, epoch step:126\n",
      "2022/03/29 14:20:59 - INFO - Distillation -  Global step: 1035, epoch step:135\n",
      "2022/03/29 14:21:01 - INFO - Distillation -  Global step: 1044, epoch step:144\n",
      "2022/03/29 14:21:02 - INFO - Distillation -  Global step: 1053, epoch step:153\n",
      "2022/03/29 14:21:04 - INFO - Distillation -  Global step: 1062, epoch step:162\n",
      "2022/03/29 14:21:06 - INFO - Distillation -  Global step: 1071, epoch step:171\n",
      "2022/03/29 14:21:07 - INFO - Distillation -  Global step: 1080, epoch step:180\n",
      "2022/03/29 14:21:07 - INFO - Distillation -  Saving at global step 1080, epoch step 180 epoch 6\n",
      "2022/03/29 14:21:08 - INFO - Distillation -  Running callback function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7247],\n",
      "        [0.9674]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.9320],\n",
      "        [4.2611]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.1678],\n",
      "        [0.9314]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.9403],\n",
      "        [1.4562]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.1566],\n",
      "        [1.8425]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5687],\n",
      "        [1.6763]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6523],\n",
      "        [1.6298]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.5430],\n",
      "        [3.2536]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.4773],\n",
      "        [2.3434]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.7192],\n",
      "        [3.0245]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.9718],\n",
      "        [4.9926]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.0443],\n",
      "        [1.1787]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.4525],\n",
      "        [1.7747]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9354],\n",
      "        [4.9890]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.4509],\n",
      "        [1.8130]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.7741],\n",
      "        [3.3709]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.8329],\n",
      "        [0.7749]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.1812],\n",
      "        [0.7335]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.0522],\n",
      "        [3.3904]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.0519],\n",
      "        [0.7641]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2991],\n",
      "        [3.0461]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7562],\n",
      "        [4.7354]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7262],\n",
      "        [1.8085]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.0452],\n",
      "        [4.7621]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.0373],\n",
      "        [3.7358]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.8762],\n",
      "        [4.7678]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.6921],\n",
      "        [2.1995]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.9918],\n",
      "        [4.0008]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6944],\n",
      "        [4.8702]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.6481],\n",
      "        [2.9208]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.7334],\n",
      "        [1.6907]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.9229],\n",
      "        [2.7719]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.2512],\n",
      "        [3.3307]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.5060],\n",
      "        [4.4221]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.0619],\n",
      "        [4.2077]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.7038],\n",
      "        [4.5057]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7808],\n",
      "        [2.1752]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.6087],\n",
      "        [0.8147]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.5954],\n",
      "        [0.5516]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.4542],\n",
      "        [1.4914]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9147],\n",
      "        [2.1947]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.7890],\n",
      "        [3.0012]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.3495],\n",
      "        [4.6290]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.0993],\n",
      "        [2.1488]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.5670],\n",
      "        [2.0791]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.9320],\n",
      "        [2.7064]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4195],\n",
      "        [4.5450]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:21:11 - INFO - Distillation -  {'pearson': 0.16042464796731964, 'spearmanr': 0.16240458524238655}\n",
      "2022/03/29 14:21:11 - INFO - Distillation -  Epoch 6 finished\n",
      "2022/03/29 14:21:11 - INFO - Distillation -  Epoch 7\n",
      "2022/03/29 14:21:11 - INFO - Distillation -  Length of current epoch in forward batch: 180\n",
      "2022/03/29 14:21:13 - INFO - Distillation -  Global step: 1089, epoch step:9\n",
      "2022/03/29 14:21:15 - INFO - Distillation -  Global step: 1098, epoch step:18\n",
      "2022/03/29 14:21:16 - INFO - Distillation -  Global step: 1107, epoch step:27\n",
      "2022/03/29 14:21:18 - INFO - Distillation -  Global step: 1116, epoch step:36\n",
      "2022/03/29 14:21:20 - INFO - Distillation -  Global step: 1125, epoch step:45\n",
      "2022/03/29 14:21:21 - INFO - Distillation -  Global step: 1134, epoch step:54\n",
      "2022/03/29 14:21:23 - INFO - Distillation -  Global step: 1143, epoch step:63\n",
      "2022/03/29 14:21:24 - INFO - Distillation -  Global step: 1152, epoch step:72\n",
      "2022/03/29 14:21:26 - INFO - Distillation -  Global step: 1161, epoch step:81\n",
      "2022/03/29 14:21:28 - INFO - Distillation -  Global step: 1170, epoch step:90\n",
      "2022/03/29 14:21:29 - INFO - Distillation -  Global step: 1179, epoch step:99\n",
      "2022/03/29 14:21:31 - INFO - Distillation -  Global step: 1188, epoch step:108\n",
      "2022/03/29 14:21:33 - INFO - Distillation -  Global step: 1197, epoch step:117\n",
      "2022/03/29 14:21:34 - INFO - Distillation -  Global step: 1206, epoch step:126\n",
      "2022/03/29 14:21:36 - INFO - Distillation -  Global step: 1215, epoch step:135\n",
      "2022/03/29 14:21:38 - INFO - Distillation -  Global step: 1224, epoch step:144\n",
      "2022/03/29 14:21:39 - INFO - Distillation -  Global step: 1233, epoch step:153\n",
      "2022/03/29 14:21:41 - INFO - Distillation -  Global step: 1242, epoch step:162\n",
      "2022/03/29 14:21:43 - INFO - Distillation -  Global step: 1251, epoch step:171\n",
      "2022/03/29 14:21:44 - INFO - Distillation -  Global step: 1260, epoch step:180\n",
      "2022/03/29 14:21:44 - INFO - Distillation -  Saving at global step 1260, epoch step 180 epoch 7\n",
      "2022/03/29 14:21:45 - INFO - Distillation -  Running callback function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7503],\n",
      "        [1.7168]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.7183],\n",
      "        [4.8514]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.5913],\n",
      "        [1.5322]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.1791],\n",
      "        [3.3263]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.5397],\n",
      "        [5.1231]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.2236],\n",
      "        [2.5083]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.2861],\n",
      "        [2.5676]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8419],\n",
      "        [3.7971]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.7863],\n",
      "        [4.6555]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.8343],\n",
      "        [4.2799]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.1150],\n",
      "        [5.1210]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.0180],\n",
      "        [1.5360]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1107],\n",
      "        [3.0869]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7843],\n",
      "        [4.9517]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8249],\n",
      "        [2.0683]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.9810],\n",
      "        [3.8963]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.5979],\n",
      "        [2.0111]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3047],\n",
      "        [1.4581]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.0228],\n",
      "        [4.2555]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.7004],\n",
      "        [1.3497]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.2359],\n",
      "        [4.3766]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.0405],\n",
      "        [5.0142]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.1002],\n",
      "        [2.9620]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8411],\n",
      "        [5.0621]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7743],\n",
      "        [5.0746]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.6841],\n",
      "        [4.6181]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.0843],\n",
      "        [3.9961]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6079],\n",
      "        [4.9418]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.0547],\n",
      "        [5.0469]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.8907],\n",
      "        [4.0908]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7994],\n",
      "        [2.7800]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.1199],\n",
      "        [2.4553]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.1319],\n",
      "        [5.0610]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.5801],\n",
      "        [4.8083]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.7535],\n",
      "        [4.8342]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.9446],\n",
      "        [5.0329]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.9603],\n",
      "        [4.1718]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.8839],\n",
      "        [2.1640]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1748],\n",
      "        [1.6914]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6435],\n",
      "        [2.4730]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3139],\n",
      "        [2.4715]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.5969],\n",
      "        [4.7186]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.7871],\n",
      "        [4.9794]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.7038],\n",
      "        [4.1587]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.3460],\n",
      "        [3.4368]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.2207],\n",
      "        [3.2195]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.0074],\n",
      "        [5.1614]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:21:48 - INFO - Distillation -  {'pearson': 0.15035060434078906, 'spearmanr': 0.15460839659506215}\n",
      "2022/03/29 14:21:48 - INFO - Distillation -  Epoch 7 finished\n",
      "2022/03/29 14:21:48 - INFO - Distillation -  Epoch 8\n",
      "2022/03/29 14:21:48 - INFO - Distillation -  Length of current epoch in forward batch: 180\n",
      "2022/03/29 14:21:50 - INFO - Distillation -  Global step: 1269, epoch step:9\n",
      "2022/03/29 14:21:52 - INFO - Distillation -  Global step: 1278, epoch step:18\n",
      "2022/03/29 14:21:53 - INFO - Distillation -  Global step: 1287, epoch step:27\n",
      "2022/03/29 14:21:55 - INFO - Distillation -  Global step: 1296, epoch step:36\n",
      "2022/03/29 14:21:56 - INFO - Distillation -  Global step: 1305, epoch step:45\n",
      "2022/03/29 14:21:58 - INFO - Distillation -  Global step: 1314, epoch step:54\n",
      "2022/03/29 14:22:00 - INFO - Distillation -  Global step: 1323, epoch step:63\n",
      "2022/03/29 14:22:01 - INFO - Distillation -  Global step: 1332, epoch step:72\n",
      "2022/03/29 14:22:03 - INFO - Distillation -  Global step: 1341, epoch step:81\n",
      "2022/03/29 14:22:05 - INFO - Distillation -  Global step: 1350, epoch step:90\n",
      "2022/03/29 14:22:06 - INFO - Distillation -  Global step: 1359, epoch step:99\n",
      "2022/03/29 14:22:08 - INFO - Distillation -  Global step: 1368, epoch step:108\n",
      "2022/03/29 14:22:10 - INFO - Distillation -  Global step: 1377, epoch step:117\n",
      "2022/03/29 14:22:12 - INFO - Distillation -  Global step: 1386, epoch step:126\n",
      "2022/03/29 14:22:13 - INFO - Distillation -  Global step: 1395, epoch step:135\n",
      "2022/03/29 14:22:15 - INFO - Distillation -  Global step: 1404, epoch step:144\n",
      "2022/03/29 14:22:17 - INFO - Distillation -  Global step: 1413, epoch step:153\n",
      "2022/03/29 14:22:18 - INFO - Distillation -  Global step: 1422, epoch step:162\n",
      "2022/03/29 14:22:20 - INFO - Distillation -  Global step: 1431, epoch step:171\n",
      "2022/03/29 14:22:21 - INFO - Distillation -  Global step: 1440, epoch step:180\n",
      "2022/03/29 14:22:21 - INFO - Distillation -  Saving at global step 1440, epoch step 180 epoch 8\n",
      "2022/03/29 14:22:23 - INFO - Distillation -  Running callback function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8871],\n",
      "        [2.9454]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.9635],\n",
      "        [5.1098]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.1273],\n",
      "        [2.4144]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.6688],\n",
      "        [4.7075]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.2130],\n",
      "        [5.2778]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.1806],\n",
      "        [3.6606]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.2122],\n",
      "        [3.5949]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.8308],\n",
      "        [5.1018]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.8810],\n",
      "        [4.5471]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.0987],\n",
      "        [4.7531]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.4768],\n",
      "        [5.3627]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.8701],\n",
      "        [1.5432]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8651],\n",
      "        [3.3598]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.3048],\n",
      "        [5.3862]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.6317],\n",
      "        [3.9082]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.3631],\n",
      "        [4.7908]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.5050],\n",
      "        [2.3335]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2702],\n",
      "        [2.1199]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.9401],\n",
      "        [5.1963]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.8164],\n",
      "        [1.5130]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.6062],\n",
      "        [4.7555]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.4278],\n",
      "        [5.2925]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.4198],\n",
      "        [2.1090]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.2705],\n",
      "        [5.3957]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.1751],\n",
      "        [5.3004]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.1111],\n",
      "        [5.1996]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.4874],\n",
      "        [4.5830]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6406],\n",
      "        [5.1996]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.4492],\n",
      "        [5.4748]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.2521],\n",
      "        [5.1110]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.1576],\n",
      "        [4.0976]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.4943],\n",
      "        [2.6469]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.3891],\n",
      "        [5.3922]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.9434],\n",
      "        [5.4021]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.5023],\n",
      "        [5.2999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.2384],\n",
      "        [5.3369]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.4598],\n",
      "        [4.3744]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.2730],\n",
      "        [5.0216]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.9109],\n",
      "        [2.2170]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7494],\n",
      "        [3.2265]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.4042],\n",
      "        [4.5946]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.5496],\n",
      "        [5.1351]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.5979],\n",
      "        [5.2426]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6164],\n",
      "        [4.9351]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.8797],\n",
      "        [4.5869]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.5856],\n",
      "        [4.5817]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:22:25 - INFO - Distillation -  {'pearson': 0.16603823840472687, 'spearmanr': 0.17297136654659473}\n",
      "2022/03/29 14:22:25 - INFO - Distillation -  Epoch 8 finished\n",
      "2022/03/29 14:22:25 - INFO - Distillation -  Epoch 9\n",
      "2022/03/29 14:22:25 - INFO - Distillation -  Length of current epoch in forward batch: 180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.2627],\n",
      "        [5.4904]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:22:27 - INFO - Distillation -  Global step: 1449, epoch step:9\n",
      "2022/03/29 14:22:28 - INFO - Distillation -  Global step: 1458, epoch step:18\n",
      "2022/03/29 14:22:30 - INFO - Distillation -  Global step: 1467, epoch step:27\n",
      "2022/03/29 14:22:32 - INFO - Distillation -  Global step: 1476, epoch step:36\n",
      "2022/03/29 14:22:33 - INFO - Distillation -  Global step: 1485, epoch step:45\n",
      "2022/03/29 14:22:35 - INFO - Distillation -  Global step: 1494, epoch step:54\n",
      "2022/03/29 14:22:37 - INFO - Distillation -  Global step: 1503, epoch step:63\n",
      "2022/03/29 14:22:39 - INFO - Distillation -  Global step: 1512, epoch step:72\n",
      "2022/03/29 14:22:40 - INFO - Distillation -  Global step: 1521, epoch step:81\n",
      "2022/03/29 14:22:42 - INFO - Distillation -  Global step: 1530, epoch step:90\n",
      "2022/03/29 14:22:44 - INFO - Distillation -  Global step: 1539, epoch step:99\n",
      "2022/03/29 14:22:45 - INFO - Distillation -  Global step: 1548, epoch step:108\n",
      "2022/03/29 14:22:47 - INFO - Distillation -  Global step: 1557, epoch step:117\n",
      "2022/03/29 14:22:49 - INFO - Distillation -  Global step: 1566, epoch step:126\n",
      "2022/03/29 14:22:50 - INFO - Distillation -  Global step: 1575, epoch step:135\n",
      "2022/03/29 14:22:52 - INFO - Distillation -  Global step: 1584, epoch step:144\n",
      "2022/03/29 14:22:53 - INFO - Distillation -  Global step: 1593, epoch step:153\n",
      "2022/03/29 14:22:55 - INFO - Distillation -  Global step: 1602, epoch step:162\n",
      "2022/03/29 14:22:57 - INFO - Distillation -  Global step: 1611, epoch step:171\n",
      "2022/03/29 14:22:58 - INFO - Distillation -  Global step: 1620, epoch step:180\n",
      "2022/03/29 14:22:58 - INFO - Distillation -  Saving at global step 1620, epoch step 180 epoch 9\n",
      "2022/03/29 14:23:00 - INFO - Distillation -  Running callback function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6802],\n",
      "        [2.2644]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.9483],\n",
      "        [4.6112]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8039],\n",
      "        [1.8317]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.3673],\n",
      "        [3.9797]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.8870],\n",
      "        [4.6993]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7265],\n",
      "        [3.5946]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.5110],\n",
      "        [2.0104]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.3760],\n",
      "        [4.8968]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.4551],\n",
      "        [4.4454]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.1010],\n",
      "        [3.1330]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.4980],\n",
      "        [5.3110]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.5325],\n",
      "        [1.5322]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6001],\n",
      "        [0.7859]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.9435],\n",
      "        [4.7854]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.5668],\n",
      "        [3.3537]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.0277],\n",
      "        [3.2830]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4008],\n",
      "        [1.7402]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.0039],\n",
      "        [1.7866]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.9583],\n",
      "        [4.9552]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6375],\n",
      "        [1.7080]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.4526],\n",
      "        [3.8252]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.4272],\n",
      "        [5.0587]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.4663],\n",
      "        [1.2980]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.8843],\n",
      "        [5.3541]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.5852],\n",
      "        [5.2544]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6420],\n",
      "        [5.3391]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.3640],\n",
      "        [4.5176]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6644],\n",
      "        [4.9155]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.2228],\n",
      "        [5.2578]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.3851],\n",
      "        [3.8052]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.8025],\n",
      "        [3.4857]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.4827],\n",
      "        [2.4226]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.1287],\n",
      "        [5.1207]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.0679],\n",
      "        [4.8055]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.9699],\n",
      "        [5.0502]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.9846],\n",
      "        [5.2395]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.3337],\n",
      "        [3.4452]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.5357],\n",
      "        [4.6347]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6101],\n",
      "        [2.1097]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.9121],\n",
      "        [1.8217]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2111],\n",
      "        [3.2617]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2147],\n",
      "        [4.9358]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.5549],\n",
      "        [4.7133]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.8657],\n",
      "        [3.8044]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.2324],\n",
      "        [4.2435]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.2584],\n",
      "        [4.4257]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:23:02 - INFO - Distillation -  {'pearson': 0.1510390726318039, 'spearmanr': 0.14478096099615667}\n",
      "2022/03/29 14:23:02 - INFO - Distillation -  Epoch 9 finished\n",
      "2022/03/29 14:23:02 - INFO - Distillation -  Epoch 10\n",
      "2022/03/29 14:23:02 - INFO - Distillation -  Length of current epoch in forward batch: 180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.7583],\n",
      "        [5.3344]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:23:04 - INFO - Distillation -  Global step: 1629, epoch step:9\n",
      "2022/03/29 14:23:05 - INFO - Distillation -  Global step: 1638, epoch step:18\n",
      "2022/03/29 14:23:07 - INFO - Distillation -  Global step: 1647, epoch step:27\n",
      "2022/03/29 14:23:09 - INFO - Distillation -  Global step: 1656, epoch step:36\n",
      "2022/03/29 14:23:10 - INFO - Distillation -  Global step: 1665, epoch step:45\n",
      "2022/03/29 14:23:12 - INFO - Distillation -  Global step: 1674, epoch step:54\n",
      "2022/03/29 14:23:14 - INFO - Distillation -  Global step: 1683, epoch step:63\n",
      "2022/03/29 14:23:16 - INFO - Distillation -  Global step: 1692, epoch step:72\n",
      "2022/03/29 14:23:17 - INFO - Distillation -  Global step: 1701, epoch step:81\n",
      "2022/03/29 14:23:19 - INFO - Distillation -  Global step: 1710, epoch step:90\n",
      "2022/03/29 14:23:20 - INFO - Distillation -  Global step: 1719, epoch step:99\n",
      "2022/03/29 14:23:22 - INFO - Distillation -  Global step: 1728, epoch step:108\n",
      "2022/03/29 14:23:24 - INFO - Distillation -  Global step: 1737, epoch step:117\n",
      "2022/03/29 14:23:25 - INFO - Distillation -  Global step: 1746, epoch step:126\n",
      "2022/03/29 14:23:27 - INFO - Distillation -  Global step: 1755, epoch step:135\n",
      "2022/03/29 14:23:29 - INFO - Distillation -  Global step: 1764, epoch step:144\n",
      "2022/03/29 14:23:30 - INFO - Distillation -  Global step: 1773, epoch step:153\n",
      "2022/03/29 14:23:32 - INFO - Distillation -  Global step: 1782, epoch step:162\n",
      "2022/03/29 14:23:34 - INFO - Distillation -  Global step: 1791, epoch step:171\n",
      "2022/03/29 14:23:35 - INFO - Distillation -  Global step: 1800, epoch step:180\n",
      "2022/03/29 14:23:35 - INFO - Distillation -  Saving at global step 1800, epoch step 180 epoch 10\n",
      "2022/03/29 14:23:37 - INFO - Distillation -  Running callback function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3746],\n",
      "        [2.6251]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0765],\n",
      "        [3.8689]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.7594],\n",
      "        [1.0383]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7385],\n",
      "        [3.9580]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.0083],\n",
      "        [3.2711]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6278],\n",
      "        [2.6898]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.7519],\n",
      "        [2.1307]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.5459],\n",
      "        [4.3594]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.9338],\n",
      "        [3.9960]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.9127],\n",
      "        [3.6011]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.3751],\n",
      "        [4.6441]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.8198],\n",
      "        [1.0071]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3227],\n",
      "        [0.4884]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.3573],\n",
      "        [3.9941]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.2780],\n",
      "        [2.8224]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6036],\n",
      "        [2.6147]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.5574],\n",
      "        [1.1043]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.3399],\n",
      "        [0.8355]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.9358],\n",
      "        [4.6633]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.3259],\n",
      "        [0.7490]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8734],\n",
      "        [3.8028]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.2023],\n",
      "        [4.8145]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.3523],\n",
      "        [0.9416]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7340],\n",
      "        [4.3516]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.0623],\n",
      "        [4.0399]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.8148],\n",
      "        [4.8506]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.1016],\n",
      "        [4.0324]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.8181],\n",
      "        [4.2691]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.8296],\n",
      "        [5.2423]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.6181],\n",
      "        [3.5764]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.5556],\n",
      "        [2.6903]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.2581],\n",
      "        [2.1879]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.6720],\n",
      "        [4.7886]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.1752],\n",
      "        [4.9753]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2244],\n",
      "        [4.7785]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.6005],\n",
      "        [5.1079]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.2283],\n",
      "        [3.6483]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.6375],\n",
      "        [3.8967]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1891],\n",
      "        [0.9905]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2864],\n",
      "        [1.4365]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.6558],\n",
      "        [2.6247]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.9232],\n",
      "        [4.5445]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.4417],\n",
      "        [4.3608]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.1839],\n",
      "        [3.8009]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.1493],\n",
      "        [4.0179]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.4191],\n",
      "        [3.4398]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.9620],\n",
      "        [5.2902]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:23:40 - INFO - Distillation -  {'pearson': 0.1271796590684155, 'spearmanr': 0.12484284405152517}\n",
      "2022/03/29 14:23:40 - INFO - Distillation -  Epoch 10 finished\n",
      "2022/03/29 14:23:40 - INFO - Distillation -  Epoch 11\n",
      "2022/03/29 14:23:40 - INFO - Distillation -  Length of current epoch in forward batch: 180\n",
      "2022/03/29 14:23:41 - INFO - Distillation -  Global step: 1809, epoch step:9\n",
      "2022/03/29 14:23:43 - INFO - Distillation -  Global step: 1818, epoch step:18\n",
      "2022/03/29 14:23:44 - INFO - Distillation -  Global step: 1827, epoch step:27\n",
      "2022/03/29 14:23:46 - INFO - Distillation -  Global step: 1836, epoch step:36\n",
      "2022/03/29 14:23:48 - INFO - Distillation -  Global step: 1845, epoch step:45\n",
      "2022/03/29 14:23:49 - INFO - Distillation -  Global step: 1854, epoch step:54\n",
      "2022/03/29 14:23:51 - INFO - Distillation -  Global step: 1863, epoch step:63\n",
      "2022/03/29 14:23:53 - INFO - Distillation -  Global step: 1872, epoch step:72\n",
      "2022/03/29 14:23:55 - INFO - Distillation -  Global step: 1881, epoch step:81\n",
      "2022/03/29 14:23:56 - INFO - Distillation -  Global step: 1890, epoch step:90\n",
      "2022/03/29 14:23:58 - INFO - Distillation -  Global step: 1899, epoch step:99\n",
      "2022/03/29 14:24:00 - INFO - Distillation -  Global step: 1908, epoch step:108\n",
      "2022/03/29 14:24:01 - INFO - Distillation -  Global step: 1917, epoch step:117\n",
      "2022/03/29 14:24:03 - INFO - Distillation -  Global step: 1926, epoch step:126\n",
      "2022/03/29 14:24:04 - INFO - Distillation -  Global step: 1935, epoch step:135\n",
      "2022/03/29 14:24:06 - INFO - Distillation -  Global step: 1944, epoch step:144\n",
      "2022/03/29 14:24:08 - INFO - Distillation -  Global step: 1953, epoch step:153\n",
      "2022/03/29 14:24:09 - INFO - Distillation -  Global step: 1962, epoch step:162\n",
      "2022/03/29 14:24:11 - INFO - Distillation -  Global step: 1971, epoch step:171\n",
      "2022/03/29 14:24:13 - INFO - Distillation -  Global step: 1980, epoch step:180\n",
      "2022/03/29 14:24:13 - INFO - Distillation -  Saving at global step 1980, epoch step 180 epoch 11\n",
      "2022/03/29 14:24:14 - INFO - Distillation -  Running callback function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2648],\n",
      "        [1.8710]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.0899],\n",
      "        [3.3422]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.2679],\n",
      "        [0.4464]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6689],\n",
      "        [3.2618]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.9060],\n",
      "        [2.6550]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.0955],\n",
      "        [2.3499]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.3423],\n",
      "        [1.5688]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.4299],\n",
      "        [4.0073]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5207],\n",
      "        [3.8147]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.3652],\n",
      "        [3.0259]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7837],\n",
      "        [4.2723]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.2780],\n",
      "        [0.6031]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.8659],\n",
      "        [0.2430]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8380],\n",
      "        [3.6852]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.3870],\n",
      "        [1.9306]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3178],\n",
      "        [1.7248]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9770],\n",
      "        [1.0867]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.0014],\n",
      "        [1.2650]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.6590],\n",
      "        [3.9298]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.0853],\n",
      "        [0.7275]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0070],\n",
      "        [3.2983]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7664],\n",
      "        [4.1485]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.1570],\n",
      "        [0.8227]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.7549],\n",
      "        [3.2249]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1909],\n",
      "        [3.3956]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.7114],\n",
      "        [4.7505]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.6367],\n",
      "        [3.5146]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.5684],\n",
      "        [3.5625]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.2178],\n",
      "        [4.8605]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.3266],\n",
      "        [3.0175]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8735],\n",
      "        [2.0252]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7525],\n",
      "        [2.4579]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8241],\n",
      "        [4.5446]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4799],\n",
      "        [4.0436]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.8813],\n",
      "        [3.8415]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.1410],\n",
      "        [4.4136]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7963],\n",
      "        [2.9946]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4858],\n",
      "        [2.7372]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.6103],\n",
      "        [1.0381]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.3963],\n",
      "        [0.7119]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.4083],\n",
      "        [2.5931]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.2637],\n",
      "        [4.0607]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.3494],\n",
      "        [3.3469]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.8910],\n",
      "        [3.2209]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.4319],\n",
      "        [2.1906]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.3649],\n",
      "        [3.2118]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:24:17 - INFO - Distillation -  {'pearson': 0.11446322398932705, 'spearmanr': 0.11222550083580439}\n",
      "2022/03/29 14:24:17 - INFO - Distillation -  Epoch 11 finished\n",
      "2022/03/29 14:24:17 - INFO - Distillation -  Epoch 12\n",
      "2022/03/29 14:24:17 - INFO - Distillation -  Length of current epoch in forward batch: 180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1623],\n",
      "        [4.9445]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:24:19 - INFO - Distillation -  Global step: 1989, epoch step:9\n",
      "2022/03/29 14:24:20 - INFO - Distillation -  Global step: 1998, epoch step:18\n",
      "2022/03/29 14:24:22 - INFO - Distillation -  Global step: 2007, epoch step:27\n",
      "2022/03/29 14:24:24 - INFO - Distillation -  Global step: 2016, epoch step:36\n",
      "2022/03/29 14:24:25 - INFO - Distillation -  Global step: 2025, epoch step:45\n",
      "2022/03/29 14:24:27 - INFO - Distillation -  Global step: 2034, epoch step:54\n",
      "2022/03/29 14:24:28 - INFO - Distillation -  Global step: 2043, epoch step:63\n",
      "2022/03/29 14:24:30 - INFO - Distillation -  Global step: 2052, epoch step:72\n",
      "2022/03/29 14:24:32 - INFO - Distillation -  Global step: 2061, epoch step:81\n",
      "2022/03/29 14:24:34 - INFO - Distillation -  Global step: 2070, epoch step:90\n",
      "2022/03/29 14:24:35 - INFO - Distillation -  Global step: 2079, epoch step:99\n",
      "2022/03/29 14:24:37 - INFO - Distillation -  Global step: 2088, epoch step:108\n",
      "2022/03/29 14:24:39 - INFO - Distillation -  Global step: 2097, epoch step:117\n",
      "2022/03/29 14:24:40 - INFO - Distillation -  Global step: 2106, epoch step:126\n",
      "2022/03/29 14:24:42 - INFO - Distillation -  Global step: 2115, epoch step:135\n",
      "2022/03/29 14:24:44 - INFO - Distillation -  Global step: 2124, epoch step:144\n",
      "2022/03/29 14:24:45 - INFO - Distillation -  Global step: 2133, epoch step:153\n",
      "2022/03/29 14:24:47 - INFO - Distillation -  Global step: 2142, epoch step:162\n",
      "2022/03/29 14:24:49 - INFO - Distillation -  Global step: 2151, epoch step:171\n",
      "2022/03/29 14:24:50 - INFO - Distillation -  Global step: 2160, epoch step:180\n",
      "2022/03/29 14:24:50 - INFO - Distillation -  Saving at global step 2160, epoch step 180 epoch 12\n",
      "2022/03/29 14:24:51 - INFO - Distillation -  Running callback function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5057],\n",
      "        [2.5131]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.6836],\n",
      "        [3.4547]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1616],\n",
      "        [0.7006]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.9997],\n",
      "        [3.3679]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7181],\n",
      "        [3.5510]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.2267],\n",
      "        [1.8641]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.3783],\n",
      "        [1.7957]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.8833],\n",
      "        [3.9538]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.8197],\n",
      "        [3.9643]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.3299],\n",
      "        [3.1884]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.5596],\n",
      "        [4.4845]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.9347],\n",
      "        [0.9189]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0406],\n",
      "        [0.4755]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8610],\n",
      "        [3.3984]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.3478],\n",
      "        [2.3959]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.1668],\n",
      "        [1.9452]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6470],\n",
      "        [1.4410]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.7644],\n",
      "        [1.4974]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0556],\n",
      "        [3.8869]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.8428],\n",
      "        [1.6820]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.2867],\n",
      "        [3.1627]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.0011],\n",
      "        [4.5617]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.0811],\n",
      "        [1.0513]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.0378],\n",
      "        [4.3746]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.9493],\n",
      "        [3.6199]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.8551],\n",
      "        [4.5883]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.8564],\n",
      "        [3.6880]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.3753],\n",
      "        [3.3666]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.8182],\n",
      "        [4.9357]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.6444],\n",
      "        [3.0511]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3480],\n",
      "        [2.8505]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7083],\n",
      "        [2.1156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.4133],\n",
      "        [4.5225]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.2864],\n",
      "        [3.9097]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.4951],\n",
      "        [3.4591]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.1144],\n",
      "        [4.6489]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.8273],\n",
      "        [3.8858]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8757],\n",
      "        [2.4547]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.2106],\n",
      "        [1.2645]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.6978],\n",
      "        [1.1205]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.2641],\n",
      "        [2.8421]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.6882],\n",
      "        [4.4552]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.8209],\n",
      "        [3.3782]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.5768],\n",
      "        [3.3024]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.5123],\n",
      "        [2.6829]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:24:54 - INFO - Distillation -  {'pearson': 0.1379913043174405, 'spearmanr': 0.13698671185194836}\n",
      "2022/03/29 14:24:54 - INFO - Distillation -  Epoch 12 finished\n",
      "2022/03/29 14:24:54 - INFO - Distillation -  Epoch 13\n",
      "2022/03/29 14:24:54 - INFO - Distillation -  Length of current epoch in forward batch: 180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8474],\n",
      "        [2.8353]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3734],\n",
      "        [4.8735]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:24:55 - INFO - Distillation -  Global step: 2169, epoch step:9\n",
      "2022/03/29 14:24:57 - INFO - Distillation -  Global step: 2178, epoch step:18\n",
      "2022/03/29 14:24:59 - INFO - Distillation -  Global step: 2187, epoch step:27\n",
      "2022/03/29 14:25:00 - INFO - Distillation -  Global step: 2196, epoch step:36\n",
      "2022/03/29 14:25:02 - INFO - Distillation -  Global step: 2205, epoch step:45\n",
      "2022/03/29 14:25:04 - INFO - Distillation -  Global step: 2214, epoch step:54\n",
      "2022/03/29 14:25:05 - INFO - Distillation -  Global step: 2223, epoch step:63\n",
      "2022/03/29 14:25:07 - INFO - Distillation -  Global step: 2232, epoch step:72\n",
      "2022/03/29 14:25:09 - INFO - Distillation -  Global step: 2241, epoch step:81\n",
      "2022/03/29 14:25:11 - INFO - Distillation -  Global step: 2250, epoch step:90\n",
      "2022/03/29 14:25:12 - INFO - Distillation -  Global step: 2259, epoch step:99\n",
      "2022/03/29 14:25:14 - INFO - Distillation -  Global step: 2268, epoch step:108\n",
      "2022/03/29 14:25:16 - INFO - Distillation -  Global step: 2277, epoch step:117\n",
      "2022/03/29 14:25:17 - INFO - Distillation -  Global step: 2286, epoch step:126\n",
      "2022/03/29 14:25:19 - INFO - Distillation -  Global step: 2295, epoch step:135\n",
      "2022/03/29 14:25:20 - INFO - Distillation -  Global step: 2304, epoch step:144\n",
      "2022/03/29 14:25:22 - INFO - Distillation -  Global step: 2313, epoch step:153\n",
      "2022/03/29 14:25:24 - INFO - Distillation -  Global step: 2322, epoch step:162\n",
      "2022/03/29 14:25:25 - INFO - Distillation -  Global step: 2331, epoch step:171\n",
      "2022/03/29 14:25:27 - INFO - Distillation -  Global step: 2340, epoch step:180\n",
      "2022/03/29 14:25:27 - INFO - Distillation -  Saving at global step 2340, epoch step 180 epoch 13\n",
      "2022/03/29 14:25:28 - INFO - Distillation -  Running callback function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3739],\n",
      "        [1.5922]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.0430],\n",
      "        [3.2531]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8281],\n",
      "        [0.3933]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.9456],\n",
      "        [3.1708]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.9048],\n",
      "        [2.5584]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.8184],\n",
      "        [1.1538]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.0791],\n",
      "        [2.1522]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0883],\n",
      "        [3.4929]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.3348],\n",
      "        [3.4817]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.1558],\n",
      "        [2.9991]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.3968],\n",
      "        [3.7929]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.0335],\n",
      "        [0.8567]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.4609],\n",
      "        [1.0140]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8960],\n",
      "        [3.2246]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.5003],\n",
      "        [2.5568]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.7422],\n",
      "        [1.5346]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.4153],\n",
      "        [1.6249]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.5302],\n",
      "        [1.1050]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.1356],\n",
      "        [3.3638]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.9540],\n",
      "        [1.4057]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.7358],\n",
      "        [3.7341]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7802],\n",
      "        [4.1456]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[5.0188],\n",
      "        [1.0104]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.8319],\n",
      "        [4.3263]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.7395],\n",
      "        [3.3694]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.5804],\n",
      "        [4.5444]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.0468],\n",
      "        [3.8357]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.4194],\n",
      "        [3.2010]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.6299],\n",
      "        [4.4294]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.5679],\n",
      "        [3.0984]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3017],\n",
      "        [2.9574]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.7472],\n",
      "        [2.2189]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.9576],\n",
      "        [3.9181]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.0058],\n",
      "        [3.5274]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.1805],\n",
      "        [3.9149]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.6335],\n",
      "        [4.5444]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.6845],\n",
      "        [3.5666]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.1878],\n",
      "        [2.8086]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.4367],\n",
      "        [0.9914]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.7933],\n",
      "        [1.1532]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.2559],\n",
      "        [2.1559]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[1.8310],\n",
      "        [3.9646]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:25:31 - INFO - Distillation -  {'pearson': 0.15679048327568396, 'spearmanr': 0.1562916699972037}\n",
      "2022/03/29 14:25:31 - INFO - Distillation -  Epoch 13 finished\n",
      "2022/03/29 14:25:31 - INFO - Distillation -  Epoch 14\n",
      "2022/03/29 14:25:31 - INFO - Distillation -  Length of current epoch in forward batch: 180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9195],\n",
      "        [3.4407]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.9867],\n",
      "        [2.8336]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[4.0901],\n",
      "        [2.8829]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[2.2244],\n",
      "        [2.9538]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[3.3252],\n",
      "        [4.7964]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/29 14:25:32 - INFO - Distillation -  Global step: 2349, epoch step:9\n",
      "2022/03/29 14:25:34 - INFO - Distillation -  Global step: 2358, epoch step:18\n",
      "2022/03/29 14:25:36 - INFO - Distillation -  Global step: 2367, epoch step:27\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2193654/3851624900.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheduler_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/work/mhessent/miniconda/envs/thesis_test/lib/python3.8/site-packages/textbrewer/distiller_basic.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, optimizer, dataloader, num_epochs, scheduler_class, scheduler_args, scheduler, max_grad_norm, num_steps, callback, batch_postprocessor, **args)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_with_num_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm_disable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_postprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_with_num_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm_disable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_postprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/mhessent/miniconda/envs/thesis_test/lib/python3.8/site-packages/textbrewer/distiller_basic.py\u001b[0m in \u001b[0;36mtrain_with_num_epochs\u001b[0;34m(self, optimizer, scheduler, tqdm_disable, dataloader, max_grad_norm, num_epochs, callback, batch_postprocessor, **args)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0mwriter_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/mhessent/miniconda/envs/thesis_test/lib/python3.8/site-packages/textbrewer/distiller_basic.py\u001b[0m in \u001b[0;36mwrite_loss\u001b[0;34m(self, total_loss, writer_step, losses_dict)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mcpu_total_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scalar/total_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlosses_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 60\n",
    "num_training_steps = len(train_dataloader) * num_epochs\n",
    "# Optimizer and learning rate scheduler\n",
    "optimizer = AdamW(student_model.parameters(), lr=1e-4)\n",
    "\n",
    "scheduler_class = get_linear_schedule_with_warmup\n",
    "# arguments dict except 'optimizer'\n",
    "scheduler_args = {'num_warmup_steps':int(0.1*num_training_steps), 'num_training_steps':num_training_steps}\n",
    "\n",
    "\n",
    "def simple_adaptor(batch, model_outputs):\n",
    "    return {'logits': model_outputs.logits, 'hidden': model_outputs.hidden_states}\n",
    "\n",
    "\n",
    "from matches import matches\n",
    "intermediate_matches = None\n",
    "match_list_L4t = [\"L4t_hidden_mse\", \"L4_hidden_smmd\"]\n",
    "match_list_L3 = [\"L3_hidden_mse\", \"L3_hidden_smmd\"]\n",
    "intermediate_matches = []\n",
    "for match in match_list_L3:\n",
    "        intermediate_matches += matches[match]\n",
    "\n",
    "distill_config = DistillationConfig(kd_loss_type='mse')#,intermediate_matches=intermediate_matches)\n",
    "train_config = TrainingConfig(device=device)\n",
    "\n",
    "\n",
    "\n",
    "task_name = \"stsb\"\n",
    "local_rank = -1\n",
    "predict_batch_size = 32\n",
    "device = device\n",
    "output_dir = \"outputs/\" + task_name + \"/\" \n",
    "eval_datasets = [val_dataset]\n",
    "\n",
    "callback_func = partial(predict, eval_datasets=eval_datasets, output_dir=output_dir,task_name=task_name,local_rank=local_rank,predict_batch_size=predict_batch_size,device=device)\n",
    "\n",
    "distiller = GeneralDistiller(\n",
    "    train_config=train_config, distill_config=distill_config,\n",
    "    model_T=teacher_model, model_S=student_model, \n",
    "    adaptor_T=simple_adaptor, adaptor_S=simple_adaptor)\n",
    "\n",
    "\n",
    "with distiller:\n",
    "    distiller.train(optimizer, train_dataloader, num_epochs, scheduler_class=scheduler_class, scheduler_args = scheduler_args, callback=callback_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textbrewer.distiller_utils import move_to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8acpGydEgLf",
    "outputId": "79a0c44f-7f03-4d6d-b09b-84a858fa1360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = RobertaForSequenceClassification(student_config)\n",
    "test_model.load_state_dict(torch.load('/work/mhessent/TextBrewer/examples/notebook_examples/saved_models/gs9900.pkl'))#gs4210 is the distilled model weights file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_5QYCFnAMkpE"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "eval_dataloader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "u0Pb4CeJdLCk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson': 0.9528690590068446, 'spearmanr': 0.948260299590721}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric= load_metric(\"glue\",\"stsb\")\n",
    "test_model.to(device)\n",
    "test_model.eval()\n",
    "for batch in train_dataloader:\n",
    "    batch = {k: v for k, v in batch.items()}\n",
    "    batch = move_to_device(batch,device)\n",
    "    with torch.no_grad():\n",
    "        outputs = test_model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    metric.add_batch(predictions=logits, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson': 0.9700052119764774, 'spearmanr': 0.9658411506535708}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#teacher_model = RobertaForSequenceClassification.from_pretrained('/work/mhessent/master_thesis/eval_out/roberta-base/stsb/lr3e-05_bs32_epochs10/checkpoint-1620')\n",
    "metric= load_metric(\"glue\",\"stsb\")\n",
    "#teacher_model.cpu()\n",
    "teacher_model.to(device)\n",
    "teacher_model.eval()\n",
    "for batch in train_dataloader:\n",
    "    batch = {k: v for k, v in batch.items()}\n",
    "    batch = move_to_device(batch,device)\n",
    "    with torch.no_grad():\n",
    "        outputs = teacher_model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    metric.add_batch(predictions=logits, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPSRVIK8638b2CgsGZ/nsAR",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1LgVQBkBlDbyTgriuZ88TDXPA6MSUKN3W",
   "name": "sst2_bert_fin.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
